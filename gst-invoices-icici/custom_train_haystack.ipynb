{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf73c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: farm-haystack in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (1.17.1)\n",
      "Requirement already satisfied: azure-ai-formrecognizer>=3.2.0b2 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (3.3.0b1)\n",
      "Requirement already satisfied: boilerpy3 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (1.0.6)\n",
      "Requirement already satisfied: canals==0.2.2 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (0.2.2)\n",
      "Requirement already satisfied: dill in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (0.3.4)\n",
      "Requirement already satisfied: events in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (0.4)\n",
      "Requirement already satisfied: generalimport==0.3.1 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (0.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.5.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (0.14.1)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (4.17.3)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (9.1.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (3.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (2.0.1)\n",
      "Requirement already satisfied: posthog in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (3.0.1)\n",
      "Requirement already satisfied: protobuf<=3.20.2 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (3.20.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (1.10.7)\n",
      "Requirement already satisfied: quantulum3 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (0.9.0)\n",
      "Requirement already satisfied: rank-bm25 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (0.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (2.30.0)\n",
      "Requirement already satisfied: requests-cache<1.0.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (0.9.8)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (1.2.2)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (2.2.2)\n",
      "Requirement already satisfied: sseclient-py in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (1.7.2)\n",
      "Requirement already satisfied: tenacity in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.2 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (0.4.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (4.65.0)\n",
      "Requirement already satisfied: transformers[torch]==4.29.1 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (4.29.1)\n",
      "Requirement already satisfied: typing-extensions==4.5.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from farm-haystack) (4.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from transformers[torch]==4.29.1->farm-haystack) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from transformers[torch]==4.29.1->farm-haystack) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from transformers[torch]==4.29.1->farm-haystack) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from transformers[torch]==4.29.1->farm-haystack) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from transformers[torch]==4.29.1->farm-haystack) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from transformers[torch]==4.29.1->farm-haystack) (0.13.3)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from transformers[torch]==4.29.1->farm-haystack) (2.0.1)\n",
      "Requirement already satisfied: accelerate>=0.19.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from transformers[torch]==4.29.1->farm-haystack) (0.20.3)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack) (1.27.0)\n",
      "Requirement already satisfied: msrest>=0.6.21 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack) (0.7.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack) (1.1.28)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from huggingface-hub>=0.5.0->farm-haystack) (2023.5.0)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from requests-cache<1.0.0->farm-haystack) (1.4.4)\n",
      "Requirement already satisfied: attrs>=21.2 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from requests-cache<1.0.0->farm-haystack) (23.1.0)\n",
      "Requirement already satisfied: cattrs>=22.2 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from requests-cache<1.0.0->farm-haystack) (23.1.2)\n",
      "Requirement already satisfied: url-normalize>=1.4 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from requests-cache<1.0.0->farm-haystack) (1.4.3)\n",
      "Requirement already satisfied: urllib3>=1.25.5 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from requests-cache<1.0.0->farm-haystack) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from requests->farm-haystack) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from requests->farm-haystack) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from requests->farm-haystack) (2023.5.7)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from scikit-learn>=1.0.0->farm-haystack) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from scikit-learn>=1.0.0->farm-haystack) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from scikit-learn>=1.0.0->farm-haystack) (3.1.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from sentence-transformers>=2.2.0->farm-haystack) (0.15.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from sentence-transformers>=2.2.0->farm-haystack) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from sentence-transformers>=2.2.0->farm-haystack) (0.1.99)\n",
      "Requirement already satisfied: colorama in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from tqdm->farm-haystack) (0.4.6)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from jsonschema->farm-haystack) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from pandas->farm-haystack) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from pandas->farm-haystack) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from pandas->farm-haystack) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from posthog->farm-haystack) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from posthog->farm-haystack) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from posthog->farm-haystack) (2.2.1)\n",
      "Requirement already satisfied: inflect in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from quantulum3->farm-haystack) (6.0.4)\n",
      "Requirement already satisfied: num2words in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from quantulum3->farm-haystack) (0.5.12)\n",
      "Requirement already satisfied: psutil in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from accelerate>=0.19.0->transformers[torch]==4.29.1->farm-haystack) (5.9.5)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack) (1.1.1)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\kapil\\appdata\\roaming\\python\\python310\\site-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack) (1.3.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]==4.29.1->farm-haystack) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]==4.29.1->farm-haystack) (3.1.2)\n",
      "Requirement already satisfied: click in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from nltk->sentence-transformers>=2.2.0->farm-haystack) (8.1.3)\n",
      "Requirement already satisfied: docopt>=0.6.2 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from num2words->quantulum3->farm-haystack) (0.6.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from torchvision->sentence-transformers>=2.2.0->farm-haystack) (9.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]==4.29.1->farm-haystack) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]==4.29.1->farm-haystack) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -lack (c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lack (c:\\users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install farm-haystack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f321c95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import FARMReader\n",
    "reader = FARMReader(model_name_or_path=\"distilbert-base-uncased-distilled-squad\", use_gpu=True)\n",
    "data_dir = \"./\"\n",
    "# data_dir = \"PATH/TO_YOUR/TRAIN_DATA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35461cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": true, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n"
     ]
    }
   ],
   "source": [
    "#reader.train(data_dir=data_dir, train_filename=\"answers_gst.json\", use_gpu=False, n_epochs=10, save_dir=\"gst_10\",)\n",
    "new_reader = FARMReader(model_name_or_path=\"gst_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101b1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''DATTATRAYA MAHARAJ KALAMBE JALOLI SAHAKARI BANK LTD. SECOND FLOOR, DMK JAOLI BANK BUILDING, HO, 418/20, MAULANA AZAD ROAD, NEAR ROUND TEMPLE, MU MBAI INVOICE DATE: 31-12-2022 CUSTOMER:ICICI BANK LTD. ADDRESS :UNIT NO 503 5TH FLOOR HALLMARKBUSINESS PLAZA SANT DNYANESHWAR MARG BANDRA E INVOICE NO: AST MUMBAI MAHARASHTRA 400051 STATE :MAHARASHTRA DMKBUP|112220045 STATE CODE :27 GSTIN :27AAACI1195HSZI SR.NO. DESCRIPTION HSN CODE DETAILS COUNT UNIT AMOUNT(RS.) INTERCHANGE RECEIVED 1 FOR THE MONTH OF DEC-22 997158 FUND TRANSFER TRANSACTIONS 15 55.30 MERCHANT TRANSACTIONS TOTAL 55.30 CGST @ 9% 4.98 SGST/UGST @9%% 4.98 IGST @ 18% 0,00 GRAND TOTAL 65.26 TOTAL (AMOUNT IN WORDS) RUPEES SIXTY FIVE AND TWENTY SIX PAISE ONLY FOR DATTATRAYA MAHARAJ KALAMBE JALOLI SAHAKARI BANK LTD. GSTIN: 27AAAAD4765G1ZR PAN: AAAAD4765G STATE: MAHARASHTRA APPROVAL SIGNATURE SIGNOR: ARVIND SURVE DATA: 28 MARCH 2023 18:34 REASON: DIGITALLY SIGNED'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedda9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline, Document\n",
    "from haystack.utils import print_answers\n",
    "# reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\")\n",
    "p = Pipeline()\n",
    "p.add_node(component=new_reader, name=\"Reader\", inputs=[\"Query\"])\n",
    "\n",
    "def find_lables(context):\n",
    "    \n",
    "    output = {}\n",
    "    lables = [\"icici gst number? \",\"pdf address?\",\"pdf bank name?\",\"pdf cgst @9?\",\"pdf igst @18?\",\\\n",
    "             \"PDF_GSTIN\t\",\"PDF_Interchange Fees\t\",\"PDF_Invoice date\t\",\"PDF_Invoice Number\",\\\n",
    "              \"PDF_SGST / UGST @ 9 %\", \"Signature Remarks\t\"]\n",
    "    for lbl in lables:\n",
    "        res = p.run(\n",
    "            query=lbl, documents=[Document(content=context)]\n",
    "        )\n",
    "        out = [x.to_dict() for x in res[\"answers\"]]\n",
    "       # print(out)\n",
    "     #   print(\"Query -> {} : Answer is -> {} with {}\".format(lbl,out[0]['answer'],out[0]['score']))\n",
    "\n",
    "        output[lbl] =  str(out[0]['answer']) + \" ==> \" +str(out[0]['score'])\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca57b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kapil\\anaconda3\\envs\\mlai1\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radio\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.77it/s]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]WARNING:haystack.modeling.model.language_model:'segment_ids' is not None, but DistilBert does not use them. They will be ignored.\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.61s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]WARNING:haystack.modeling.model.language_model:'segment_ids' is not None, but DistilBert does not use them. They will be ignored.\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.30s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]WARNING:haystack.modeling.model.language_model:'segment_ids' is not None, but DistilBert does not use them. They will be ignored.\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]WARNING:haystack.modeling.model.language_model:'segment_ids' is not None, but DistilBert does not use them. They will be ignored.\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.63s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]WARNING:haystack.modeling.model.language_model:'segment_ids' is not None, but DistilBert does not use them. They will be ignored.\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.39s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]WARNING:haystack.modeling.model.language_model:'segment_ids' is not None, but DistilBert does not use them. They will be ignored.\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.37s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]WARNING:haystack.modeling.model.language_model:'segment_ids' is not None, but DistilBert does not use them. They will be ignored.\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.35s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]WARNING:haystack.modeling.model.language_model:'segment_ids' is not None, but DistilBert does not use them. They will be ignored.\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.33s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]WARNING:haystack.modeling.model.language_model:'segment_ids' is not None, but DistilBert does not use them. They will be ignored.\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.30s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]WARNING:haystack.modeling.model.language_model:'segment_ids' is not None, but DistilBert does not use them. They will be ignored.\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/ Batches]\n",
      "Inferencing Samples:   0%|                                                                 | 0/1 [00:00<?, ? Batches/s]WARNING:haystack.modeling.model.language_model:'segment_ids' is not None, but DistilBert does not use them. They will be ignored.\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.34s/ Batches]\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "model_ocr = ocr_predictor(det_arch='db_resnet50', reco_arch='crnn_vgg16_bn', pretrained=True)\n",
    "import itertools\n",
    "import warnings\n",
    "import gradio as gr\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cv2,requests,time,json,glob\n",
    "import numpy as np\n",
    "from pathlib import Path    \n",
    "\n",
    "import fitz\n",
    "from tqdm import tqdm\n",
    "\n",
    "subscription_key = \"cd9de642c81c46ddbe6509ad84c9b621\"#\"8b77eadc000640d4a292194794995dc6\"#\"94e072db7b7f451f82252fa11686c1e5\" #\"cd9de642c81c46ddbe6509ad84c9b621\"\n",
    "text_recognition_url = \"https://centralindia.api.cognitive.microsoft.com/vision/v2.0/read/core/asyncBatchAnalyze\"\n",
    "\n",
    "Path(\"images\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def find_ocr_ms(filename):\n",
    "\n",
    "  doc = fitz.open(filename)\n",
    "  \n",
    "  images = []\n",
    "\n",
    "  try:\n",
    "   for page in tqdm(doc):\n",
    "\n",
    "\n",
    "      pm = page.get_pixmap(matrix=fitz.Identity, alpha=False)\n",
    "   #   print(\"images/samplepdfimage-%i.jpg\" % page.number)\n",
    "      images.append(\"images/samplepdfimage-%i.jpg\" % page.number)\n",
    "      pm.save(\"images/samplepdfimage-%i.jpg\" % page.number)  # save file\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  total_ocr = []\n",
    "  for i,filename in enumerate(images):\n",
    "          image_url = cv2.imread(filename)           # GIVE IMAGE PATH HERE\n",
    "          out_path = Path(filename).name\n",
    "        #  print(out_path)\n",
    "\n",
    "          \n",
    "          success, encoded_image = cv2.imencode('.jpg', image_url)\n",
    "          image_data = encoded_image.tobytes()    \t\t\t\t\t\t\t\t\n",
    "          headers = {'Ocp-Apim-Subscription-Key': subscription_key,\n",
    "                'Content-Type': 'application/octet-stream'}\n",
    "          params = {'visualFeatures': 'Categories,Description,Color','language': 'unk'}\n",
    "          response = requests.post(text_recognition_url, headers=headers, params=params, data=image_data)\n",
    "          response.raise_for_status()\n",
    "       \n",
    "          operation_url = response.headers[\"Operation-Location\"]\n",
    "          \n",
    "          analysis = {}\n",
    "          poll = True\n",
    "          raw = []\n",
    "          while (poll):\n",
    "              response_final = requests.get(operation_url, headers=headers)\n",
    "              analysis = response_final.json()\n",
    "              time.sleep(0.1)\n",
    "              if (\"recognitionResults\" in analysis):\n",
    "                  poll= False \n",
    "              if (\"status\" in analysis and analysis['status'] == 'Failed'):\n",
    "                  poll= False\n",
    "          \n",
    "          polygons=[]\n",
    "          if (\"recognitionResults\" in analysis):\n",
    "              polygons = [(line[\"boundingBox\"], line[\"text\"])\n",
    "                          for line in analysis[\"recognitionResults\"][0][\"lines\"]]\n",
    "          \n",
    "          \n",
    "          words = []\n",
    "          for polygon in polygons:\n",
    "              vertices = [(polygon[0][i], polygon[0][i+1])\n",
    "                          for i in range(0, len(polygon[0]), 2)]\n",
    "              start_pt,end_pt = vertices[0], vertices[2]\n",
    "              text     = polygon[1].upper()\n",
    "              words.append((text))\n",
    "  return \" \".join(words)             \n",
    " # my_path = Path('images')\n",
    " # my_path.rmtree(ignore_errors=True)\n",
    "\n",
    "\n",
    "def find_ocr(file):\n",
    "    print(file.name)\n",
    "    doc = DocumentFile.from_pdf(str(file.name))\n",
    "\n",
    "    # Analyze\n",
    "    result = model_ocr(doc)\n",
    "\n",
    "#    result = model(doc[5:6])\n",
    "    json_output = result.export()\n",
    "    words_loc_normalized = []\n",
    "    corpus = []\n",
    "    for ii in range (len(json_output['pages'])):\n",
    "      for d in json_output.values():\n",
    "          num_blocks = len(d[ii]['blocks'])\n",
    "      #    print(num_blocks)\n",
    "  \n",
    "          for k in range (num_blocks):\n",
    "          \n",
    "            row = d[ii]['blocks'][k]['lines']\n",
    "      #      print(row)\n",
    "            res = \" \".join([k['value'] for item in row for k in item['words']])\n",
    "         #   print(res)\n",
    "            corpus.append(res)\n",
    "            \n",
    "    return \" \".join(corpus)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "     \n",
    " \n",
    "    with gr.Blocks() as demo:\n",
    "    \n",
    "         file = gr.File()\n",
    "         docs = gr.Radio([\"corporate_gurantee\",\"gst_invoices\"], label=\"Doc_type\")\n",
    "         print(docs)\n",
    "    \n",
    "         output = gr.Textbox()\n",
    "         btn = gr.Button(value=\"Get OCR\")\n",
    "         btn.click(find_ocr_ms, inputs=[file], outputs=[output])\n",
    "         \n",
    "         with gr.Row():\n",
    "             output2 = gr.JSON()\n",
    "    \n",
    "         btn = gr.Button(value=\"Extract info\")\n",
    "         btn.click(find_lables, inputs=[output], outputs=[output2])\n",
    "         \n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4466a055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
